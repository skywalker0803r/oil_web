{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LTIlE23rfWAn"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from torch.nn import Linear,ReLU,Sigmoid\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from math import sqrt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import warnings;warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "aUQT_bCRfYyA",
    "outputId": "0843ef9e-5a03-42de-bed4-d4c07007f2c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4691, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T10</th>\n",
       "      <th>T50</th>\n",
       "      <th>T90</th>\n",
       "      <th>N+A</th>\n",
       "      <th>C5NP</th>\n",
       "      <th>C5IP</th>\n",
       "      <th>C5N</th>\n",
       "      <th>C6NP</th>\n",
       "      <th>C6IP</th>\n",
       "      <th>C6N</th>\n",
       "      <th>...</th>\n",
       "      <th>C8N</th>\n",
       "      <th>C8A</th>\n",
       "      <th>C9NP</th>\n",
       "      <th>C9IP</th>\n",
       "      <th>C9N</th>\n",
       "      <th>C9A</th>\n",
       "      <th>C10NP</th>\n",
       "      <th>C10IP</th>\n",
       "      <th>C10N</th>\n",
       "      <th>C10A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.5</td>\n",
       "      <td>119.2</td>\n",
       "      <td>146.5</td>\n",
       "      <td>31.978</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.059</td>\n",
       "      <td>5.293</td>\n",
       "      <td>2.570</td>\n",
       "      <td>2.819</td>\n",
       "      <td>...</td>\n",
       "      <td>4.810</td>\n",
       "      <td>5.373</td>\n",
       "      <td>6.405</td>\n",
       "      <td>9.759</td>\n",
       "      <td>4.590</td>\n",
       "      <td>3.661</td>\n",
       "      <td>0.875</td>\n",
       "      <td>5.257</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>99.6</td>\n",
       "      <td>117.9</td>\n",
       "      <td>145.5</td>\n",
       "      <td>31.568</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.062</td>\n",
       "      <td>5.089</td>\n",
       "      <td>2.531</td>\n",
       "      <td>2.804</td>\n",
       "      <td>...</td>\n",
       "      <td>4.753</td>\n",
       "      <td>5.443</td>\n",
       "      <td>6.324</td>\n",
       "      <td>9.899</td>\n",
       "      <td>4.301</td>\n",
       "      <td>2.995</td>\n",
       "      <td>0.881</td>\n",
       "      <td>5.591</td>\n",
       "      <td>1.119</td>\n",
       "      <td>0.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>118.8</td>\n",
       "      <td>145.6</td>\n",
       "      <td>31.344</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.061</td>\n",
       "      <td>5.107</td>\n",
       "      <td>2.571</td>\n",
       "      <td>2.771</td>\n",
       "      <td>...</td>\n",
       "      <td>4.778</td>\n",
       "      <td>5.468</td>\n",
       "      <td>6.360</td>\n",
       "      <td>9.983</td>\n",
       "      <td>4.274</td>\n",
       "      <td>2.979</td>\n",
       "      <td>0.865</td>\n",
       "      <td>5.641</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100.4</td>\n",
       "      <td>118.6</td>\n",
       "      <td>142.9</td>\n",
       "      <td>31.453</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.060</td>\n",
       "      <td>4.894</td>\n",
       "      <td>2.497</td>\n",
       "      <td>2.650</td>\n",
       "      <td>...</td>\n",
       "      <td>4.889</td>\n",
       "      <td>5.510</td>\n",
       "      <td>6.444</td>\n",
       "      <td>10.182</td>\n",
       "      <td>4.420</td>\n",
       "      <td>2.964</td>\n",
       "      <td>0.830</td>\n",
       "      <td>5.637</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100.4</td>\n",
       "      <td>118.1</td>\n",
       "      <td>142.2</td>\n",
       "      <td>32.190</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.061</td>\n",
       "      <td>4.946</td>\n",
       "      <td>2.503</td>\n",
       "      <td>2.695</td>\n",
       "      <td>...</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5.500</td>\n",
       "      <td>6.416</td>\n",
       "      <td>10.115</td>\n",
       "      <td>4.347</td>\n",
       "      <td>3.725</td>\n",
       "      <td>0.835</td>\n",
       "      <td>4.823</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     T10    T50    T90     N+A   C5NP   C5IP    C5N   C6NP   C6IP    C6N  ...  \\\n",
       "0  100.5  119.2  146.5  31.978  0.272  0.132  0.059  5.293  2.570  2.819  ...   \n",
       "1   99.6  117.9  145.5  31.568  0.297  0.151  0.062  5.089  2.531  2.804  ...   \n",
       "2  100.0  118.8  145.6  31.344  0.262  0.126  0.061  5.107  2.571  2.771  ...   \n",
       "3  100.4  118.6  142.9  31.453  0.224  0.105  0.060  4.894  2.497  2.650  ...   \n",
       "4  100.4  118.1  142.2  32.190  0.243  0.117  0.061  4.946  2.503  2.695  ...   \n",
       "\n",
       "     C8N    C8A   C9NP    C9IP    C9N    C9A  C10NP  C10IP   C10N   C10A  \n",
       "0  4.810  5.373  6.405   9.759  4.590  3.661  0.875  5.257  0.525  0.319  \n",
       "1  4.753  5.443  6.324   9.899  4.301  2.995  0.881  5.591  1.119  0.303  \n",
       "2  4.778  5.468  6.360   9.983  4.274  2.979  0.865  5.641  0.964  0.289  \n",
       "3  4.889  5.510  6.444  10.182  4.420  2.964  0.830  5.637  0.968  0.281  \n",
       "4  4.855  5.500  6.416  10.115  4.347  3.725  0.835  4.823  0.969  0.290  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./train_4521.csv',index_col=0).append(pd.read_csv('./test_170.csv',index_col=0))\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SF1jJEEMf2gr"
   },
   "source": [
    "# define columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nhuix1Mbfybb"
   },
   "outputs": [],
   "source": [
    "x_cols = df.columns.tolist()[:4]\n",
    "t_cols = df.columns.tolist()[:3]\n",
    "y_cols = df.columns.tolist()[4:]\n",
    "\n",
    "Na_feeds = ['C5N',\n",
    "          'C6N','C6A',\n",
    "          'C7N','C7A',\n",
    "          'C8N','C8A',\n",
    "          'C9N','C9A',\n",
    "          'C10N','C10A']\n",
    "\n",
    "P_feeds =  ['C5NP','C5IP',\n",
    "           'C6NP','C6IP',\n",
    "           'C7NP','C7IP',\n",
    "           'C8NP','C8IP',\n",
    "           'C9NP','C9IP',\n",
    "           'C10NP','C10IP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the P columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T10</th>\n",
       "      <th>T50</th>\n",
       "      <th>T90</th>\n",
       "      <th>N+A</th>\n",
       "      <th>P</th>\n",
       "      <th>C5NP</th>\n",
       "      <th>C5IP</th>\n",
       "      <th>C5N</th>\n",
       "      <th>C6NP</th>\n",
       "      <th>C6IP</th>\n",
       "      <th>...</th>\n",
       "      <th>C8N</th>\n",
       "      <th>C8A</th>\n",
       "      <th>C9NP</th>\n",
       "      <th>C9IP</th>\n",
       "      <th>C9N</th>\n",
       "      <th>C9A</th>\n",
       "      <th>C10NP</th>\n",
       "      <th>C10IP</th>\n",
       "      <th>C10N</th>\n",
       "      <th>C10A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>100.5</td>\n",
       "      <td>119.2</td>\n",
       "      <td>146.5</td>\n",
       "      <td>31.978</td>\n",
       "      <td>67.815</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.059</td>\n",
       "      <td>5.293</td>\n",
       "      <td>2.570</td>\n",
       "      <td>...</td>\n",
       "      <td>4.810</td>\n",
       "      <td>5.373</td>\n",
       "      <td>6.405</td>\n",
       "      <td>9.759</td>\n",
       "      <td>4.590</td>\n",
       "      <td>3.661</td>\n",
       "      <td>0.875</td>\n",
       "      <td>5.257</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>99.6</td>\n",
       "      <td>117.9</td>\n",
       "      <td>145.5</td>\n",
       "      <td>31.568</td>\n",
       "      <td>67.313</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.062</td>\n",
       "      <td>5.089</td>\n",
       "      <td>2.531</td>\n",
       "      <td>...</td>\n",
       "      <td>4.753</td>\n",
       "      <td>5.443</td>\n",
       "      <td>6.324</td>\n",
       "      <td>9.899</td>\n",
       "      <td>4.301</td>\n",
       "      <td>2.995</td>\n",
       "      <td>0.881</td>\n",
       "      <td>5.591</td>\n",
       "      <td>1.119</td>\n",
       "      <td>0.303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>118.8</td>\n",
       "      <td>145.6</td>\n",
       "      <td>31.344</td>\n",
       "      <td>67.494</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.061</td>\n",
       "      <td>5.107</td>\n",
       "      <td>2.571</td>\n",
       "      <td>...</td>\n",
       "      <td>4.778</td>\n",
       "      <td>5.468</td>\n",
       "      <td>6.360</td>\n",
       "      <td>9.983</td>\n",
       "      <td>4.274</td>\n",
       "      <td>2.979</td>\n",
       "      <td>0.865</td>\n",
       "      <td>5.641</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>100.4</td>\n",
       "      <td>118.6</td>\n",
       "      <td>142.9</td>\n",
       "      <td>31.453</td>\n",
       "      <td>67.354</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.060</td>\n",
       "      <td>4.894</td>\n",
       "      <td>2.497</td>\n",
       "      <td>...</td>\n",
       "      <td>4.889</td>\n",
       "      <td>5.510</td>\n",
       "      <td>6.444</td>\n",
       "      <td>10.182</td>\n",
       "      <td>4.420</td>\n",
       "      <td>2.964</td>\n",
       "      <td>0.830</td>\n",
       "      <td>5.637</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>100.4</td>\n",
       "      <td>118.1</td>\n",
       "      <td>142.2</td>\n",
       "      <td>32.190</td>\n",
       "      <td>66.593</td>\n",
       "      <td>0.243</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.061</td>\n",
       "      <td>4.946</td>\n",
       "      <td>2.503</td>\n",
       "      <td>...</td>\n",
       "      <td>4.855</td>\n",
       "      <td>5.500</td>\n",
       "      <td>6.416</td>\n",
       "      <td>10.115</td>\n",
       "      <td>4.347</td>\n",
       "      <td>3.725</td>\n",
       "      <td>0.835</td>\n",
       "      <td>4.823</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     T10    T50    T90     N+A       P   C5NP   C5IP    C5N   C6NP   C6IP  \\\n",
       "0  100.5  119.2  146.5  31.978  67.815  0.272  0.132  0.059  5.293  2.570   \n",
       "1   99.6  117.9  145.5  31.568  67.313  0.297  0.151  0.062  5.089  2.531   \n",
       "2  100.0  118.8  145.6  31.344  67.494  0.262  0.126  0.061  5.107  2.571   \n",
       "3  100.4  118.6  142.9  31.453  67.354  0.224  0.105  0.060  4.894  2.497   \n",
       "4  100.4  118.1  142.2  32.190  66.593  0.243  0.117  0.061  4.946  2.503   \n",
       "\n",
       "   ...    C8N    C8A   C9NP    C9IP    C9N    C9A  C10NP  C10IP   C10N   C10A  \n",
       "0  ...  4.810  5.373  6.405   9.759  4.590  3.661  0.875  5.257  0.525  0.319  \n",
       "1  ...  4.753  5.443  6.324   9.899  4.301  2.995  0.881  5.591  1.119  0.303  \n",
       "2  ...  4.778  5.468  6.360   9.983  4.274  2.979  0.865  5.641  0.964  0.289  \n",
       "3  ...  4.889  5.510  6.444  10.182  4.420  2.964  0.830  5.637  0.968  0.281  \n",
       "4  ...  4.855  5.500  6.416  10.115  4.347  3.725  0.835  4.823  0.969  0.290  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['P'] = df[y_cols].sum(axis=1) - df['N+A']\n",
    "df = df[t_cols+['N+A','P']+y_cols]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZD-z6rQDwLqS"
   },
   "source": [
    "# scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "8brqYFq7wLyg",
    "outputId": "20444d1e-bbaf-4b86-a212-5d91bb4ffe10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T10</th>\n",
       "      <th>T50</th>\n",
       "      <th>T90</th>\n",
       "      <th>N+A</th>\n",
       "      <th>P</th>\n",
       "      <th>raw_Na</th>\n",
       "      <th>raw_P</th>\n",
       "      <th>C5N</th>\n",
       "      <th>C6N</th>\n",
       "      <th>C6A</th>\n",
       "      <th>...</th>\n",
       "      <th>C6NP</th>\n",
       "      <th>C6IP</th>\n",
       "      <th>C7NP</th>\n",
       "      <th>C7IP</th>\n",
       "      <th>C8NP</th>\n",
       "      <th>C8IP</th>\n",
       "      <th>C9NP</th>\n",
       "      <th>C9IP</th>\n",
       "      <th>C10NP</th>\n",
       "      <th>C10IP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.431544</td>\n",
       "      <td>0.534148</td>\n",
       "      <td>0.475925</td>\n",
       "      <td>-1.033682</td>\n",
       "      <td>1.101289</td>\n",
       "      <td>31.978</td>\n",
       "      <td>67.815</td>\n",
       "      <td>0.059</td>\n",
       "      <td>2.819</td>\n",
       "      <td>0.494</td>\n",
       "      <td>...</td>\n",
       "      <td>5.293</td>\n",
       "      <td>2.570</td>\n",
       "      <td>10.395</td>\n",
       "      <td>8.070</td>\n",
       "      <td>9.138</td>\n",
       "      <td>9.649</td>\n",
       "      <td>6.405</td>\n",
       "      <td>9.759</td>\n",
       "      <td>0.875</td>\n",
       "      <td>5.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.348725</td>\n",
       "      <td>0.331610</td>\n",
       "      <td>0.239113</td>\n",
       "      <td>-1.082954</td>\n",
       "      <td>1.041408</td>\n",
       "      <td>31.568</td>\n",
       "      <td>67.313</td>\n",
       "      <td>0.062</td>\n",
       "      <td>2.804</td>\n",
       "      <td>0.499</td>\n",
       "      <td>...</td>\n",
       "      <td>5.089</td>\n",
       "      <td>2.531</td>\n",
       "      <td>10.074</td>\n",
       "      <td>7.958</td>\n",
       "      <td>8.970</td>\n",
       "      <td>9.548</td>\n",
       "      <td>6.324</td>\n",
       "      <td>9.899</td>\n",
       "      <td>0.881</td>\n",
       "      <td>5.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.385533</td>\n",
       "      <td>0.471829</td>\n",
       "      <td>0.262794</td>\n",
       "      <td>-1.109873</td>\n",
       "      <td>1.062999</td>\n",
       "      <td>31.344</td>\n",
       "      <td>67.494</td>\n",
       "      <td>0.061</td>\n",
       "      <td>2.771</td>\n",
       "      <td>0.492</td>\n",
       "      <td>...</td>\n",
       "      <td>5.107</td>\n",
       "      <td>2.571</td>\n",
       "      <td>10.069</td>\n",
       "      <td>7.913</td>\n",
       "      <td>9.006</td>\n",
       "      <td>9.591</td>\n",
       "      <td>6.360</td>\n",
       "      <td>9.983</td>\n",
       "      <td>0.865</td>\n",
       "      <td>5.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.422342</td>\n",
       "      <td>0.440669</td>\n",
       "      <td>-0.376600</td>\n",
       "      <td>-1.096774</td>\n",
       "      <td>1.046298</td>\n",
       "      <td>31.453</td>\n",
       "      <td>67.354</td>\n",
       "      <td>0.060</td>\n",
       "      <td>2.650</td>\n",
       "      <td>0.469</td>\n",
       "      <td>...</td>\n",
       "      <td>4.894</td>\n",
       "      <td>2.497</td>\n",
       "      <td>10.015</td>\n",
       "      <td>7.685</td>\n",
       "      <td>9.133</td>\n",
       "      <td>9.708</td>\n",
       "      <td>6.444</td>\n",
       "      <td>10.182</td>\n",
       "      <td>0.830</td>\n",
       "      <td>5.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.422342</td>\n",
       "      <td>0.362770</td>\n",
       "      <td>-0.542369</td>\n",
       "      <td>-1.008205</td>\n",
       "      <td>0.955521</td>\n",
       "      <td>32.190</td>\n",
       "      <td>66.593</td>\n",
       "      <td>0.061</td>\n",
       "      <td>2.695</td>\n",
       "      <td>0.477</td>\n",
       "      <td>...</td>\n",
       "      <td>4.946</td>\n",
       "      <td>2.503</td>\n",
       "      <td>10.053</td>\n",
       "      <td>7.765</td>\n",
       "      <td>9.101</td>\n",
       "      <td>9.676</td>\n",
       "      <td>6.416</td>\n",
       "      <td>10.115</td>\n",
       "      <td>0.835</td>\n",
       "      <td>4.823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        T10       T50       T90       N+A         P  raw_Na   raw_P    C5N  \\\n",
       "0  0.431544  0.534148  0.475925 -1.033682  1.101289  31.978  67.815  0.059   \n",
       "1  0.348725  0.331610  0.239113 -1.082954  1.041408  31.568  67.313  0.062   \n",
       "2  0.385533  0.471829  0.262794 -1.109873  1.062999  31.344  67.494  0.061   \n",
       "3  0.422342  0.440669 -0.376600 -1.096774  1.046298  31.453  67.354  0.060   \n",
       "4  0.422342  0.362770 -0.542369 -1.008205  0.955521  32.190  66.593  0.061   \n",
       "\n",
       "     C6N    C6A  ...   C6NP   C6IP    C7NP   C7IP   C8NP   C8IP   C9NP  \\\n",
       "0  2.819  0.494  ...  5.293  2.570  10.395  8.070  9.138  9.649  6.405   \n",
       "1  2.804  0.499  ...  5.089  2.531  10.074  7.958  8.970  9.548  6.324   \n",
       "2  2.771  0.492  ...  5.107  2.571  10.069  7.913  9.006  9.591  6.360   \n",
       "3  2.650  0.469  ...  4.894  2.497  10.015  7.685  9.133  9.708  6.444   \n",
       "4  2.695  0.477  ...  4.946  2.503  10.053  7.765  9.101  9.676  6.416   \n",
       "\n",
       "     C9IP  C10NP  C10IP  \n",
       "0   9.759  0.875  5.257  \n",
       "1   9.899  0.881  5.591  \n",
       "2   9.983  0.865  5.641  \n",
       "3  10.182  0.830  5.637  \n",
       "4  10.115  0.835  4.823  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "df['raw_Na'] = df['N+A']\n",
    "df['raw_P'] = df['P']\n",
    "df[t_cols+['N+A','P']] = ss.fit_transform(df[t_cols+['N+A','P']])\n",
    "df = df[t_cols+['N+A','P','raw_Na','raw_P']+Na_feeds+P_feeds]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rrScDuBNn6N4"
   },
   "source": [
    "# split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Z4YE_Th6n6Uo",
    "outputId": "bb9babfd-5997-4474-b5b0-5a4f77ff7b03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4521, 7)\n",
      "(170, 7)\n",
      "(4521, 23)\n",
      "(170, 23)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[t_cols+['N+A','P','raw_Na','raw_P']].to_numpy()\n",
    "Y = df[Na_feeds+P_feeds].to_numpy()\n",
    "\n",
    "X_train = X[:-170,:]\n",
    "X_test = X[-170:,:]\n",
    "Y_train = Y[:-170,:]\n",
    "Y_test = Y[-170:,:]\n",
    "\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F-Mmx8nQogmI"
   },
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ERz3U-5yogtP"
   },
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.float)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xVsd8C2IhIKB"
   },
   "source": [
    "# data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AnOg6MeVgnQE"
   },
   "outputs": [],
   "source": [
    "datasets = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_iter = torch.utils.data.DataLoader(datasets, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w7pJsRwshV6a"
   },
   "source": [
    "# Construct the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_FC_net(T_dim):\n",
    "    net = torch.nn.Sequential(\n",
    "        Linear(T_dim,128),ReLU(),\n",
    "        Linear(128,128),ReLU(),\n",
    "        Linear(128,T_dim),Sigmoid(),\n",
    "      )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_Na_net(input_shape,output_shape):\n",
    "    net = torch.nn.Sequential(\n",
    "        Linear(input_shape,128),ReLU(),\n",
    "        Linear(128,128),ReLU(),\n",
    "        Linear(128,128),ReLU(),\n",
    "        Linear(128,output_shape)\n",
    "      )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_P_net(input_shape,output_shape):\n",
    "    net = torch.nn.Sequential(\n",
    "        Linear(input_shape,128),ReLU(),\n",
    "        Linear(128,128),ReLU(),\n",
    "        Linear(128,128),ReLU(),\n",
    "        Linear(128,output_shape)\n",
    "      )\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fetch(x):\n",
    "    return x[:,:5],x[:,[5]],x[:,[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5_3YZ0KgnSw"
   },
   "outputs": [],
   "source": [
    "class Dual_net(nn.Module):\n",
    "    def __init__(self,T_dim,Na_dim,P_dim):\n",
    "        super(Dual_net,self).__init__()\n",
    "        self.fc = build_FC_net(T_dim)\n",
    "        self.Na_w = build_Na_net(T_dim,Na_dim) \n",
    "        self.P_w = build_P_net(T_dim,P_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x,Na_f,P_f = Fetch(x)\n",
    "        x = self.fc(x)\n",
    "        Na = F.softmax(self.Na_w(x),dim=1)*Na_f\n",
    "        P = F.softmax(self.P_w(x),dim=1)*P_f\n",
    "        return torch.cat((Na,P),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hXS2vIDkf_q"
   },
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        try:\n",
    "            m.bias.data.fill_(0)\n",
    "        except:\n",
    "            print(m,'no bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "id": "2XKjjfJ7gnVN",
    "outputId": "beeefed4-c47d-458d-cdc6-2a6b284ac7fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dual_net(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=5, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       "  (Na_w): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=11, bias=True)\n",
       "  )\n",
       "  (P_w): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Dual_net(5,11,12)\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with SummaryWriter(comment='Net1')as w:\n",
    "    w.add_graph(net, (X_train,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A_cRckt3mtsF"
   },
   "source": [
    "# loss_function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7-pwb-GJ0Mrg"
   },
   "outputs": [],
   "source": [
    "class RMSELoss(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RMSELoss,self).__init__()\n",
    "\n",
    "    def forward(self,x,y):\n",
    "        criterion = nn.MSELoss()\n",
    "        loss = torch.sqrt(criterion(x, y))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Od_3nhT3gng1"
   },
   "outputs": [],
   "source": [
    "loss_function = RMSELoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_FH8xJsVnEqr"
   },
   "source": [
    "# Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLD-m6xfgnih"
   },
   "outputs": [],
   "source": [
    "def train(net,train_iter,loss_function,optimizer,num_epochs=100):\n",
    "  history = []\n",
    "  for epoch in range(num_epochs):\n",
    "    for x,y in train_iter:\n",
    "      loss = loss_function(net(x),y)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "    # end for\n",
    "    print(\"epochs {} loss {:.4f}\".format(epoch,loss.item()))\n",
    "    if loss.item() < 0.35:\n",
    "      break\n",
    "    history.append(loss.item())\n",
    "  # end for\n",
    "  plt.plot(np.array(history))\n",
    "  plt.title('train loss')\n",
    "  return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tzQFbEE4gtFw",
    "outputId": "d63dbf63-5373-484b-d480-67fcd95d5664"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 0 loss 3.3955\n",
      "epochs 1 loss 2.0210\n",
      "epochs 2 loss 1.4508\n",
      "epochs 3 loss 1.2711\n",
      "epochs 4 loss 1.2326\n",
      "epochs 5 loss 1.0857\n",
      "epochs 6 loss 0.9202\n",
      "epochs 7 loss 0.9653\n",
      "epochs 8 loss 0.8367\n",
      "epochs 9 loss 0.9647\n",
      "epochs 10 loss 1.5272\n",
      "epochs 11 loss 1.0488\n",
      "epochs 12 loss 0.7991\n",
      "epochs 13 loss 0.6526\n",
      "epochs 14 loss 0.7442\n",
      "epochs 15 loss 0.5517\n",
      "epochs 16 loss 0.7993\n",
      "epochs 17 loss 1.0612\n",
      "epochs 18 loss 0.6121\n",
      "epochs 19 loss 0.8447\n",
      "epochs 20 loss 0.5997\n",
      "epochs 21 loss 0.5447\n",
      "epochs 22 loss 0.5723\n",
      "epochs 23 loss 0.7897\n",
      "epochs 24 loss 0.6437\n",
      "epochs 25 loss 0.7740\n",
      "epochs 26 loss 0.5233\n",
      "epochs 27 loss 0.6865\n",
      "epochs 28 loss 0.5684\n",
      "epochs 29 loss 0.6326\n",
      "epochs 30 loss 0.7553\n",
      "epochs 31 loss 0.6935\n",
      "epochs 32 loss 0.6202\n",
      "epochs 33 loss 1.2312\n",
      "epochs 34 loss 0.7249\n",
      "epochs 35 loss 1.3768\n",
      "epochs 36 loss 0.8070\n",
      "epochs 37 loss 0.5181\n",
      "epochs 38 loss 0.5097\n",
      "epochs 39 loss 0.4508\n",
      "epochs 40 loss 0.5044\n",
      "epochs 41 loss 0.5914\n",
      "epochs 42 loss 0.4885\n",
      "epochs 43 loss 0.5104\n",
      "epochs 44 loss 0.4565\n",
      "epochs 45 loss 0.8156\n",
      "epochs 46 loss 0.3531\n",
      "epochs 47 loss 0.7419\n",
      "epochs 48 loss 0.4848\n",
      "epochs 49 loss 0.4773\n",
      "epochs 50 loss 0.4906\n",
      "epochs 51 loss 0.5578\n",
      "epochs 52 loss 0.7549\n",
      "epochs 53 loss 0.4832\n",
      "epochs 54 loss 0.7835\n",
      "epochs 55 loss 0.6147\n",
      "epochs 56 loss 1.1906\n",
      "epochs 57 loss 0.8307\n",
      "epochs 58 loss 0.6440\n",
      "epochs 59 loss 1.1928\n",
      "epochs 60 loss 0.5252\n",
      "epochs 61 loss 0.4829\n",
      "epochs 62 loss 0.4129\n",
      "epochs 63 loss 0.5497\n",
      "epochs 64 loss 0.6205\n",
      "epochs 65 loss 1.0531\n",
      "epochs 66 loss 0.7204\n",
      "epochs 67 loss 0.5586\n",
      "epochs 68 loss 0.5935\n",
      "epochs 69 loss 0.4660\n",
      "epochs 70 loss 0.5145\n",
      "epochs 71 loss 0.3957\n",
      "epochs 72 loss 0.7826\n",
      "epochs 73 loss 0.4316\n",
      "epochs 74 loss 0.5014\n",
      "epochs 75 loss 0.7214\n",
      "epochs 76 loss 1.3640\n",
      "epochs 77 loss 0.5918\n",
      "epochs 78 loss 0.4503\n",
      "epochs 79 loss 0.4459\n",
      "epochs 80 loss 0.4011\n",
      "epochs 81 loss 0.4518\n",
      "epochs 82 loss 0.4257\n",
      "epochs 83 loss 0.4977\n",
      "epochs 84 loss 0.4668\n",
      "epochs 85 loss 0.4208\n",
      "epochs 86 loss 0.8859\n",
      "epochs 87 loss 0.4941\n",
      "epochs 88 loss 1.1289\n",
      "epochs 89 loss 0.4654\n",
      "epochs 90 loss 0.5614\n",
      "epochs 91 loss 0.4032\n",
      "epochs 92 loss 0.4594\n",
      "epochs 93 loss 0.5031\n",
      "epochs 94 loss 0.5891\n",
      "epochs 95 loss 0.6285\n",
      "epochs 96 loss 0.9539\n",
      "epochs 97 loss 1.4733\n",
      "epochs 98 loss 0.4694\n",
      "epochs 99 loss 0.4714\n",
      "epochs 100 loss 0.5071\n",
      "epochs 101 loss 1.3711\n",
      "epochs 102 loss 0.8225\n",
      "epochs 103 loss 0.4598\n",
      "epochs 104 loss 0.4548\n",
      "epochs 105 loss 0.4512\n",
      "epochs 106 loss 0.4266\n",
      "epochs 107 loss 0.8803\n",
      "epochs 108 loss 0.5829\n",
      "epochs 109 loss 1.1509\n",
      "epochs 110 loss 0.4698\n",
      "epochs 111 loss 0.4674\n",
      "epochs 112 loss 0.4226\n",
      "epochs 113 loss 0.5088\n",
      "epochs 114 loss 0.4762\n",
      "epochs 115 loss 0.4228\n",
      "epochs 116 loss 0.4046\n",
      "epochs 117 loss 0.4463\n",
      "epochs 118 loss 0.4736\n",
      "epochs 119 loss 0.3678\n",
      "epochs 120 loss 0.4227\n",
      "epochs 121 loss 0.4918\n",
      "epochs 122 loss 0.5313\n",
      "epochs 123 loss 0.4263\n",
      "epochs 124 loss 0.4497\n",
      "epochs 125 loss 0.7002\n",
      "epochs 126 loss 0.5111\n",
      "epochs 127 loss 0.4907\n",
      "epochs 128 loss 0.4208\n",
      "epochs 129 loss 0.9142\n",
      "epochs 130 loss 0.5978\n",
      "epochs 131 loss 1.0701\n",
      "epochs 132 loss 0.4230\n",
      "epochs 133 loss 0.4459\n",
      "epochs 134 loss 0.4603\n",
      "epochs 135 loss 0.6303\n",
      "epochs 136 loss 0.4437\n",
      "epochs 137 loss 0.4270\n",
      "epochs 138 loss 0.9640\n",
      "epochs 139 loss 0.4523\n",
      "epochs 140 loss 1.1231\n",
      "epochs 141 loss 0.5714\n",
      "epochs 142 loss 1.3173\n",
      "epochs 143 loss 1.2112\n",
      "epochs 144 loss 0.5472\n",
      "epochs 145 loss 0.4356\n",
      "epochs 146 loss 0.3892\n",
      "epochs 147 loss 0.6984\n",
      "epochs 148 loss 0.5877\n",
      "epochs 149 loss 0.4657\n",
      "epochs 150 loss 0.6161\n",
      "epochs 151 loss 0.5099\n",
      "epochs 152 loss 0.8639\n",
      "epochs 153 loss 0.4802\n",
      "epochs 154 loss 0.5095\n",
      "epochs 155 loss 1.1587\n",
      "epochs 156 loss 1.3466\n",
      "epochs 157 loss 0.5394\n",
      "epochs 158 loss 0.5430\n",
      "epochs 159 loss 0.6386\n",
      "epochs 160 loss 0.3847\n",
      "epochs 161 loss 0.3528\n",
      "epochs 162 loss 0.3940\n",
      "epochs 163 loss 0.4401\n",
      "epochs 164 loss 0.3554\n",
      "epochs 165 loss 0.6433\n",
      "epochs 166 loss 0.4018\n",
      "epochs 167 loss 0.4151\n",
      "epochs 168 loss 0.8092\n",
      "epochs 169 loss 1.2484\n",
      "epochs 170 loss 0.4392\n",
      "epochs 171 loss 0.3847\n",
      "epochs 172 loss 0.3636\n",
      "epochs 173 loss 0.4223\n",
      "epochs 174 loss 0.3825\n",
      "epochs 175 loss 1.2068\n",
      "epochs 176 loss 0.3618\n",
      "epochs 177 loss 1.2195\n",
      "epochs 178 loss 0.5963\n",
      "epochs 179 loss 0.4380\n",
      "epochs 180 loss 1.5358\n",
      "epochs 181 loss 0.4168\n",
      "epochs 182 loss 0.3985\n",
      "epochs 183 loss 0.4644\n",
      "epochs 184 loss 0.4245\n",
      "epochs 185 loss 0.4387\n",
      "epochs 186 loss 0.6304\n",
      "epochs 187 loss 0.5123\n",
      "epochs 188 loss 0.4448\n",
      "epochs 189 loss 0.4645\n",
      "epochs 190 loss 0.4332\n",
      "epochs 191 loss 0.3603\n",
      "epochs 192 loss 0.4154\n",
      "epochs 193 loss 0.4320\n",
      "epochs 194 loss 0.4506\n",
      "epochs 195 loss 0.3720\n",
      "epochs 196 loss 0.5747\n",
      "epochs 197 loss 0.6293\n",
      "epochs 198 loss 0.3666\n",
      "epochs 199 loss 0.4264\n",
      "epochs 200 loss 0.4056\n",
      "epochs 201 loss 0.5734\n",
      "epochs 202 loss 0.4300\n",
      "epochs 203 loss 1.0113\n",
      "epochs 204 loss 0.4990\n",
      "epochs 205 loss 0.4022\n",
      "epochs 206 loss 0.7314\n",
      "epochs 207 loss 0.5281\n",
      "epochs 208 loss 0.3761\n",
      "epochs 209 loss 0.4592\n",
      "epochs 210 loss 0.7484\n",
      "epochs 211 loss 0.4235\n",
      "epochs 212 loss 0.5160\n",
      "epochs 213 loss 0.4184\n",
      "epochs 214 loss 0.4897\n",
      "epochs 215 loss 0.5378\n",
      "epochs 216 loss 0.3779\n",
      "epochs 217 loss 0.3871\n",
      "epochs 218 loss 0.3961\n",
      "epochs 219 loss 0.5306\n",
      "epochs 220 loss 0.4208\n",
      "epochs 221 loss 0.7436\n",
      "epochs 222 loss 0.4971\n",
      "epochs 223 loss 0.4178\n",
      "epochs 224 loss 0.4309\n",
      "epochs 225 loss 0.6821\n",
      "epochs 226 loss 1.1966\n",
      "epochs 227 loss 0.6744\n",
      "epochs 228 loss 0.8788\n",
      "epochs 229 loss 0.3707\n",
      "epochs 230 loss 1.4335\n",
      "epochs 231 loss 0.4229\n",
      "epochs 232 loss 0.5877\n",
      "epochs 233 loss 0.8811\n",
      "epochs 234 loss 0.3194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dual_net(\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=5, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       "  (Na_w): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=11, bias=True)\n",
       "  )\n",
       "  (P_w): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=128, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(net,train_iter,loss_function,optimizer,num_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4vCKTKGpacL"
   },
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cvd94KrEgtHw"
   },
   "outputs": [],
   "source": [
    "y_pred = net(X_test).detach().numpy()\n",
    "y_real = Y_test.detach().numpy()\n",
    "y_pred = pd.DataFrame(y_pred,columns=Na_feeds+P_feeds)[y_cols]\n",
    "y_real = pd.DataFrame(y_real,columns=Na_feeds+P_feeds)[y_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "DvuDtKyNgtLR",
    "outputId": "abf693a0-288a-4c4a-cab6-5315bbcf4105"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C5NP</th>\n",
       "      <th>C5IP</th>\n",
       "      <th>C5N</th>\n",
       "      <th>C6NP</th>\n",
       "      <th>C6IP</th>\n",
       "      <th>C6N</th>\n",
       "      <th>C6A</th>\n",
       "      <th>C7NP</th>\n",
       "      <th>C7IP</th>\n",
       "      <th>C7N</th>\n",
       "      <th>...</th>\n",
       "      <th>C8N</th>\n",
       "      <th>C8A</th>\n",
       "      <th>C9NP</th>\n",
       "      <th>C9IP</th>\n",
       "      <th>C9N</th>\n",
       "      <th>C9A</th>\n",
       "      <th>C10NP</th>\n",
       "      <th>C10IP</th>\n",
       "      <th>C10N</th>\n",
       "      <th>C10A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.218175</td>\n",
       "      <td>0.804179</td>\n",
       "      <td>0.200861</td>\n",
       "      <td>3.569877</td>\n",
       "      <td>2.444232</td>\n",
       "      <td>3.671813</td>\n",
       "      <td>0.680499</td>\n",
       "      <td>7.643855</td>\n",
       "      <td>6.285509</td>\n",
       "      <td>9.483529</td>\n",
       "      <td>...</td>\n",
       "      <td>7.174806</td>\n",
       "      <td>5.671141</td>\n",
       "      <td>5.178936</td>\n",
       "      <td>9.271562</td>\n",
       "      <td>5.111723</td>\n",
       "      <td>3.419493</td>\n",
       "      <td>1.306507</td>\n",
       "      <td>5.478330</td>\n",
       "      <td>0.784866</td>\n",
       "      <td>0.844724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.207327</td>\n",
       "      <td>0.150245</td>\n",
       "      <td>0.101153</td>\n",
       "      <td>3.357776</td>\n",
       "      <td>1.169760</td>\n",
       "      <td>2.090370</td>\n",
       "      <td>0.532529</td>\n",
       "      <td>10.315860</td>\n",
       "      <td>7.600760</td>\n",
       "      <td>6.511845</td>\n",
       "      <td>...</td>\n",
       "      <td>5.085316</td>\n",
       "      <td>5.437231</td>\n",
       "      <td>6.644370</td>\n",
       "      <td>10.651224</td>\n",
       "      <td>4.572262</td>\n",
       "      <td>3.708489</td>\n",
       "      <td>1.142899</td>\n",
       "      <td>5.985440</td>\n",
       "      <td>0.623698</td>\n",
       "      <td>0.631177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.198639</td>\n",
       "      <td>0.144921</td>\n",
       "      <td>0.100238</td>\n",
       "      <td>3.314239</td>\n",
       "      <td>1.146432</td>\n",
       "      <td>1.963161</td>\n",
       "      <td>0.516365</td>\n",
       "      <td>10.330749</td>\n",
       "      <td>7.538255</td>\n",
       "      <td>6.317244</td>\n",
       "      <td>...</td>\n",
       "      <td>4.918911</td>\n",
       "      <td>5.302519</td>\n",
       "      <td>6.815921</td>\n",
       "      <td>10.741239</td>\n",
       "      <td>4.474842</td>\n",
       "      <td>3.733623</td>\n",
       "      <td>1.245057</td>\n",
       "      <td>6.262026</td>\n",
       "      <td>0.627412</td>\n",
       "      <td>0.664733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.214946</td>\n",
       "      <td>0.157088</td>\n",
       "      <td>0.093878</td>\n",
       "      <td>3.633533</td>\n",
       "      <td>1.259435</td>\n",
       "      <td>1.990401</td>\n",
       "      <td>0.533042</td>\n",
       "      <td>10.231061</td>\n",
       "      <td>7.424918</td>\n",
       "      <td>6.264221</td>\n",
       "      <td>...</td>\n",
       "      <td>4.894280</td>\n",
       "      <td>5.451458</td>\n",
       "      <td>6.799095</td>\n",
       "      <td>10.855042</td>\n",
       "      <td>4.431532</td>\n",
       "      <td>3.712256</td>\n",
       "      <td>1.153200</td>\n",
       "      <td>6.208136</td>\n",
       "      <td>0.588542</td>\n",
       "      <td>0.597588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.229216</td>\n",
       "      <td>0.164824</td>\n",
       "      <td>0.101211</td>\n",
       "      <td>3.427446</td>\n",
       "      <td>1.236192</td>\n",
       "      <td>2.053726</td>\n",
       "      <td>0.542749</td>\n",
       "      <td>10.064695</td>\n",
       "      <td>7.346848</td>\n",
       "      <td>6.473253</td>\n",
       "      <td>...</td>\n",
       "      <td>5.051979</td>\n",
       "      <td>5.676019</td>\n",
       "      <td>6.658256</td>\n",
       "      <td>10.708039</td>\n",
       "      <td>4.514557</td>\n",
       "      <td>3.834061</td>\n",
       "      <td>1.228541</td>\n",
       "      <td>6.235176</td>\n",
       "      <td>0.630781</td>\n",
       "      <td>0.668120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       C5NP      C5IP       C5N      C6NP      C6IP       C6N       C6A  \\\n",
       "0  1.218175  0.804179  0.200861  3.569877  2.444232  3.671813  0.680499   \n",
       "1  0.207327  0.150245  0.101153  3.357776  1.169760  2.090370  0.532529   \n",
       "2  0.198639  0.144921  0.100238  3.314239  1.146432  1.963161  0.516365   \n",
       "3  0.214946  0.157088  0.093878  3.633533  1.259435  1.990401  0.533042   \n",
       "4  0.229216  0.164824  0.101211  3.427446  1.236192  2.053726  0.542749   \n",
       "\n",
       "        C7NP      C7IP       C7N  ...       C8N       C8A      C9NP  \\\n",
       "0   7.643855  6.285509  9.483529  ...  7.174806  5.671141  5.178936   \n",
       "1  10.315860  7.600760  6.511845  ...  5.085316  5.437231  6.644370   \n",
       "2  10.330749  7.538255  6.317244  ...  4.918911  5.302519  6.815921   \n",
       "3  10.231061  7.424918  6.264221  ...  4.894280  5.451458  6.799095   \n",
       "4  10.064695  7.346848  6.473253  ...  5.051979  5.676019  6.658256   \n",
       "\n",
       "        C9IP       C9N       C9A     C10NP     C10IP      C10N      C10A  \n",
       "0   9.271562  5.111723  3.419493  1.306507  5.478330  0.784866  0.844724  \n",
       "1  10.651224  4.572262  3.708489  1.142899  5.985440  0.623698  0.631177  \n",
       "2  10.741239  4.474842  3.733623  1.245057  6.262026  0.627412  0.664733  \n",
       "3  10.855042  4.431532  3.712256  1.153200  6.208136  0.588542  0.597588  \n",
       "4  10.708039  4.514557  3.834061  1.228541  6.235176  0.630781  0.668120  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "eZ5G24bvgtNf",
    "outputId": "f2b592b7-e6e3-47f6-d34d-acba29e15727"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C5NP</th>\n",
       "      <th>C5IP</th>\n",
       "      <th>C5N</th>\n",
       "      <th>C6NP</th>\n",
       "      <th>C6IP</th>\n",
       "      <th>C6N</th>\n",
       "      <th>C6A</th>\n",
       "      <th>C7NP</th>\n",
       "      <th>C7IP</th>\n",
       "      <th>C7N</th>\n",
       "      <th>...</th>\n",
       "      <th>C8N</th>\n",
       "      <th>C8A</th>\n",
       "      <th>C9NP</th>\n",
       "      <th>C9IP</th>\n",
       "      <th>C9N</th>\n",
       "      <th>C9A</th>\n",
       "      <th>C10NP</th>\n",
       "      <th>C10IP</th>\n",
       "      <th>C10N</th>\n",
       "      <th>C10A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.142</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.217</td>\n",
       "      <td>3.745</td>\n",
       "      <td>2.577</td>\n",
       "      <td>4.028</td>\n",
       "      <td>0.557</td>\n",
       "      <td>7.669</td>\n",
       "      <td>5.9900</td>\n",
       "      <td>10.206</td>\n",
       "      <td>...</td>\n",
       "      <td>7.039</td>\n",
       "      <td>5.438</td>\n",
       "      <td>5.263</td>\n",
       "      <td>9.537</td>\n",
       "      <td>4.877</td>\n",
       "      <td>3.481</td>\n",
       "      <td>1.088</td>\n",
       "      <td>5.652</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.029</td>\n",
       "      <td>3.955</td>\n",
       "      <td>1.563</td>\n",
       "      <td>2.407</td>\n",
       "      <td>0.400</td>\n",
       "      <td>10.016</td>\n",
       "      <td>7.2633</td>\n",
       "      <td>6.573</td>\n",
       "      <td>...</td>\n",
       "      <td>5.135</td>\n",
       "      <td>5.482</td>\n",
       "      <td>6.793</td>\n",
       "      <td>10.850</td>\n",
       "      <td>4.308</td>\n",
       "      <td>3.963</td>\n",
       "      <td>1.069</td>\n",
       "      <td>6.025</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.020</td>\n",
       "      <td>3.920</td>\n",
       "      <td>1.447</td>\n",
       "      <td>2.296</td>\n",
       "      <td>0.396</td>\n",
       "      <td>10.236</td>\n",
       "      <td>7.3480</td>\n",
       "      <td>6.259</td>\n",
       "      <td>...</td>\n",
       "      <td>4.942</td>\n",
       "      <td>5.453</td>\n",
       "      <td>6.947</td>\n",
       "      <td>10.996</td>\n",
       "      <td>4.269</td>\n",
       "      <td>3.997</td>\n",
       "      <td>1.034</td>\n",
       "      <td>6.107</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.021</td>\n",
       "      <td>3.900</td>\n",
       "      <td>1.437</td>\n",
       "      <td>2.274</td>\n",
       "      <td>0.397</td>\n",
       "      <td>10.259</td>\n",
       "      <td>7.3560</td>\n",
       "      <td>6.234</td>\n",
       "      <td>...</td>\n",
       "      <td>4.928</td>\n",
       "      <td>5.476</td>\n",
       "      <td>6.953</td>\n",
       "      <td>11.026</td>\n",
       "      <td>4.264</td>\n",
       "      <td>3.982</td>\n",
       "      <td>1.013</td>\n",
       "      <td>6.054</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.015</td>\n",
       "      <td>3.873</td>\n",
       "      <td>1.369</td>\n",
       "      <td>2.206</td>\n",
       "      <td>0.489</td>\n",
       "      <td>10.213</td>\n",
       "      <td>7.3190</td>\n",
       "      <td>6.009</td>\n",
       "      <td>...</td>\n",
       "      <td>4.769</td>\n",
       "      <td>6.584</td>\n",
       "      <td>6.866</td>\n",
       "      <td>10.892</td>\n",
       "      <td>4.169</td>\n",
       "      <td>4.227</td>\n",
       "      <td>0.930</td>\n",
       "      <td>5.828</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    C5NP   C5IP    C5N   C6NP   C6IP    C6N    C6A    C7NP    C7IP     C7N  \\\n",
       "0  1.142  0.616  0.217  3.745  2.577  4.028  0.557   7.669  5.9900  10.206   \n",
       "1  0.122  0.078  0.029  3.955  1.563  2.407  0.400  10.016  7.2633   6.573   \n",
       "2  0.098  0.064  0.020  3.920  1.447  2.296  0.396  10.236  7.3480   6.259   \n",
       "3  0.122  0.085  0.021  3.900  1.437  2.274  0.397  10.259  7.3560   6.234   \n",
       "4  0.072  0.049  0.015  3.873  1.369  2.206  0.489  10.213  7.3190   6.009   \n",
       "\n",
       "   ...    C8N    C8A   C9NP    C9IP    C9N    C9A  C10NP  C10IP   C10N   C10A  \n",
       "0  ...  7.039  5.438  5.263   9.537  4.877  3.481  1.088  5.652  0.618  0.597  \n",
       "1  ...  5.135  5.482  6.793  10.850  4.308  3.963  1.069  6.025  0.585  0.484  \n",
       "2  ...  4.942  5.453  6.947  10.996  4.269  3.997  1.034  6.107  0.543  0.456  \n",
       "3  ...  4.928  5.476  6.953  11.026  4.264  3.982  1.013  6.054  0.545  0.449  \n",
       "4  ...  4.769  6.584  6.866  10.892  4.169  4.227  0.930  5.828  0.519  0.463  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 793
    },
    "colab_type": "code",
    "id": "nG5bJe9BpJYC",
    "outputId": "c0f48085-0379-41fe-9371-f59fd6c0965a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>C5NP</td>\n",
       "      <td>0.885352</td>\n",
       "      <td>0.28936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C5IP</td>\n",
       "      <td>0.730554</td>\n",
       "      <td>0.265627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C5N</td>\n",
       "      <td>0.652415</td>\n",
       "      <td>0.0807095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C6NP</td>\n",
       "      <td>0.105856</td>\n",
       "      <td>0.382565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C6IP</td>\n",
       "      <td>0.866397</td>\n",
       "      <td>0.382061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C6N</td>\n",
       "      <td>0.914406</td>\n",
       "      <td>0.484498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C6A</td>\n",
       "      <td>0.365977</td>\n",
       "      <td>0.13604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C7NP</td>\n",
       "      <td>0.984824</td>\n",
       "      <td>0.270926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C7IP</td>\n",
       "      <td>0.839617</td>\n",
       "      <td>0.442531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C7N</td>\n",
       "      <td>0.959346</td>\n",
       "      <td>0.840259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C7A</td>\n",
       "      <td>0.763523</td>\n",
       "      <td>0.225987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C8NP</td>\n",
       "      <td>0.981797</td>\n",
       "      <td>0.233178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C8IP</td>\n",
       "      <td>0.957588</td>\n",
       "      <td>0.321543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C8N</td>\n",
       "      <td>0.898605</td>\n",
       "      <td>0.581083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C8A</td>\n",
       "      <td>0.367494</td>\n",
       "      <td>0.646475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C9NP</td>\n",
       "      <td>0.990768</td>\n",
       "      <td>0.153603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C9IP</td>\n",
       "      <td>0.958446</td>\n",
       "      <td>0.322391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C9N</td>\n",
       "      <td>0.656739</td>\n",
       "      <td>0.473122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C9A</td>\n",
       "      <td>0.492162</td>\n",
       "      <td>0.431821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C10NP</td>\n",
       "      <td>0.371481</td>\n",
       "      <td>0.167608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C10IP</td>\n",
       "      <td>0.858441</td>\n",
       "      <td>0.384412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C10N</td>\n",
       "      <td>0.495808</td>\n",
       "      <td>0.0927142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>C10A</td>\n",
       "      <td>0.237699</td>\n",
       "      <td>0.203505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AVG</td>\n",
       "      <td>0.71023</td>\n",
       "      <td>0.339653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             R2       RMSE\n",
       "C5NP   0.885352    0.28936\n",
       "C5IP   0.730554   0.265627\n",
       "C5N    0.652415  0.0807095\n",
       "C6NP   0.105856   0.382565\n",
       "C6IP   0.866397   0.382061\n",
       "C6N    0.914406   0.484498\n",
       "C6A    0.365977    0.13604\n",
       "C7NP   0.984824   0.270926\n",
       "C7IP   0.839617   0.442531\n",
       "C7N    0.959346   0.840259\n",
       "C7A    0.763523   0.225987\n",
       "C8NP   0.981797   0.233178\n",
       "C8IP   0.957588   0.321543\n",
       "C8N    0.898605   0.581083\n",
       "C8A    0.367494   0.646475\n",
       "C9NP   0.990768   0.153603\n",
       "C9IP   0.958446   0.322391\n",
       "C9N    0.656739   0.473122\n",
       "C9A    0.492162   0.431821\n",
       "C10NP  0.371481   0.167608\n",
       "C10IP  0.858441   0.384412\n",
       "C10N   0.495808  0.0927142\n",
       "C10A   0.237699   0.203505\n",
       "AVG     0.71023   0.339653"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(index=y_cols,columns=['R2','RMSE'])\n",
    "for i in y_cols:\n",
    "  res.loc[i,'R2'] = r2_score(y_real[i],y_pred[i])\n",
    "  res.loc[i,'RMSE'] = sqrt(mean_squared_error(y_real[i],y_pred[i]))\n",
    "res.loc['AVG'] = res.mean(axis=0)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "dfS8DEPNp5JF",
    "outputId": "457ad81f-56f8-408e-a176-3a0bd0f575da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40.132999</td>\n",
       "      <td>40.132999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32.174999</td>\n",
       "      <td>32.174995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>31.427998</td>\n",
       "      <td>31.427999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>31.389997</td>\n",
       "      <td>31.389996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>32.417999</td>\n",
       "      <td>32.417999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>53.841000</td>\n",
       "      <td>53.841003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>53.442001</td>\n",
       "      <td>53.442005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>52.549004</td>\n",
       "      <td>52.549000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>49.827003</td>\n",
       "      <td>49.827003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>51.437000</td>\n",
       "      <td>51.437004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          real       pred\n",
       "0    40.132999  40.132999\n",
       "1    32.174999  32.174995\n",
       "2    31.427998  31.427999\n",
       "3    31.389997  31.389996\n",
       "4    32.417999  32.417999\n",
       "..         ...        ...\n",
       "165  53.841000  53.841003\n",
       "166  53.442001  53.442005\n",
       "167  52.549004  52.549000\n",
       "168  49.827003  49.827003\n",
       "169  51.437000  51.437004\n",
       "\n",
       "[170 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp['real'] = y_real[Na_feeds].sum(axis=1).values\n",
    "temp['pred'] = y_pred[Na_feeds].sum(axis=1).values\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "pytorch_model-V3(duel).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
